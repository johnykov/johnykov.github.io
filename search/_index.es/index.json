[{"categories":null,"content":"As typical NodeJS fan I\u0026rsquo;m not following closely their release notes. That\u0026rsquo;s why I go easy way and often read another bloggers posts. Seems that NodeJS blog or docs aren\u0026rsquo;t so comfortable to read. I found beautiful Pawel Grzybek blog with some handful NodeJS news. I find those useful and worth recommendation.\nA few of interesting posts by Pawel:\nYou might not need Jest — the Node.js native test runner is great nodejs watch pnpm Looks like pnpm is gaining popularity and aims to be replacing npm. And there is no longer need for\nnodemon - is replaced with --watch dotenv - is replaced with --env-file mocha - since v20 standard lib provides test runner and more other interesting posts\nMigration from single content files to Hugo page bundles From Jekyll to Hugo! From GitHub Pages to Netlify! args parser console.log(\u0026#39;that\\\u0026#39;s so great\u0026#39;); ","permalink":"https://johnykov.github.io/posts/good-nodejs-news-blog-ref/","tags":["blogging","nodejs"],"title":"NodeJS News Blog Ref"},{"categories":null,"content":"This post might have multiple titles. \u0026ldquo;How to speed up rails project CI build times\u0026rdquo;, \u0026ldquo;How to reduce docker images size\u0026rdquo;, \u0026ldquo;How to save planet by reducing carbon print with smaller docker containers\u0026rdquo; and so on.\nOptimizing Continous Delivery process is somewhat of my passion. I think it\u0026rsquo;s the strong influence one book by Jez Humble\u0026rsquo;s put on me.\nWhen I started helping VAS (first key OSO\u0026rsquo;s client) with going cloud I wrote TBH very inefficient process of release. The complete build of docker images took place inside 3 phase Dockerfile which at best took 40 minutes to complete. Downloading gems, downloading nodejs packages, precompiling assets ended up with almost 2 GB docker image which was shipped to kubernetes cluster with the help of fluxcd. The second part of the inefficiency was our git flow process which we had. Standard develop, feature, release, and main git branches each triggered docker image re-build individually. After feature branch passed code review and got merged to develop the build process started to prepare image to deploy to dev environment. When preparing a batch of commit to ship to prod we first created release- branch which also triggered another build process (this time of release- branch) to deploy to uat env. And finally after merge to main branch prod build was triggered. 3x 40 minutes each, building docker image from scratch, downloading everything from web without any middle tier package registry. On purpose I won\u0026rsquo;t write how much time unit tests took which were running in separate github workflow and which also had dedicated dockerfile with postgres and chrome. We worked with this setup quite a long time. There were some attempts to cache and re-use final docker images which result in big ECR bills due to high data transfers.\nThe first thought that helps with moving towards better process is \u0026ldquo;promote currently built images\u0026rdquo;. We annotate each docker image with tags like dev-x.x.x which is semi semver style with environment prefix. This is one of the default flux strategies we took from the shelf. So basically annotating docker image with uat- or prod- prefixes is a way to tell flux listener to deploy accordingly. This single step helped to save 2x 40 minutes of build times of uat- and prod- images.\nAnother step is to get rid of middle layer docker images for assets precompilation and github cache utilization. Our final docker images are alpine linux distro and we are building app on ubuntu-latest. Both are x86 architecture both are linuxes. However bundler complains about some native packages for alpine and requires additional bundle install invocation but that action moved to the very end of the process helps a lot. The biggest gains are due to caches of gems, node packages and precompiled assets. Github actions caches name is created basing on hashFiles function. So until no changes are applied to any of TS, JS, TSX or yarn.lock files the assets are taken from cache. Additional benefit is there are no node_modules on final docker image. Only public/ directory. Modified dockerfile contains 2 phases and first one runs \u0026ldquo;bundle clean\u0026rdquo; which will remove development and test gems used only for build,test time.\nThe complete build process went down to 5-6minutes and I see another optimization which would take previous docker image and only copy /app directory to it if no frontend changes. Final docker image is now 446 MB size. And we track that number in ever build summary.\nTests execution was parallelized and whole suite was split into 15 groups with matrix github workflow directive and \u0026ndash;only-group flag for parallel_rspec. Rspec examples in groups are not well balanced in terms of execution times but right now the whole tests suit takes as long as the longest group which is usually up to 10 minutes.\nThis app contains a few popular gems like device, sidekiq, draper, aasm, rolify, activeadmin, react-rails, turbo-rails. I find this very satisfying when seeing cost savings, shorter image transfer times and overall quicker build times.\n","permalink":"https://johnykov.github.io/posts/efficient-ci-pipeline-with-github-actions/","tags":["flux","rails","github actions","CI"],"title":"Efficient CI pipeline With Github Actions"},{"categories":null,"content":"Yesterday I\u0026rsquo;ve attended a DDD-WAW meetup with Andrzej Krzywda from Arkency which was great. Andrzej is a great guy. I’ve met him first time in real. Andrzej was talking about his programming career. He is a good storyteller. He was of course talking a lot about DDD and how they do it in Arkency. He showed off some examples. Pointed us to demo app of the DDD/CQRS/ES patterns applied - e-commerce . Before yesterdays talk I listened to his interview on Mateusz Gil’s podcast on spotify. Thus I knew what to expect. I’ve got 3 takeaways from that talk.\nI should read a book by Martin Fowler named Refactoring. (I got this on my shelf since a few years) Another called E-Myth by Gerber - to help understand our business clients way of thinking. I should try Copilot from Github. DDD concept is known to me. I tried to learn it from either of books blue one by Eric Evans and red one by Vaughn Vernon. I failed on both. Someone from the audience recommended a Hands-on Domain-driven Design - by example by Michael Plot. Maybe I will give it a go. I find DDD more appealing to me as a hexagonal apps. If you are not familiar I really recommend this great article Hexagonal Architecture There are other great articles on the web on that topic. Essentially it’s putting all the core business logic into POROs (or in Java case POJOs), in good named modules and build a structure of an app NOT by technical role as it’s in default generated rails app. Some say it’s also a good practice in other technologies for example in NodeJS you can find Project Structure by self-contained component role . TBH I find it so good that it should be applied in every single project. I\u0026rsquo;ve learned this concept a few years ago thanks to Kent C Dodds from his egghead course introducing to webpack. I was migrating Bootzooka grunt or gulp to webpack back then. I think this is a rule which Kevlin Henney strongly emphasize. He is a great man.\nExtracting business logic from framework objects. That is a great concept of clean code with quick tests but hard to achieve IMO. It requires a lot of code hygiene and discipline. I find it as an alternative to the classic ActiveRecord pattern proposed by Rails guru DHH. Of course it requires some balance and taste to decide when to go with that.\nThat DDD-WAW group (in Warsaw) is set by very pleasant gentlemen Przemek and Marcin. The second comes from dotNet world as I understood. He occasionally gives talks there, on meetup group strictly dedicated to .Net. That is why there were a lot of people on DDD-WAW meetup from around that area. It was great to meet excited coders live.\nOn the way home I\u0026rsquo;ve listened amazing podcast From Kubernetes to PaaS - now what? From which I took 2 recommendations:\nI should give a try to move from nvm, rvm to asdf tool which is a package version manager for multiple tools I should learn more about nixOS - A few years back my friend praised it but it was a black magic for me back then ","permalink":"https://johnykov.github.io/posts/ddd-waw-and-from-kubernetes-to-paas/","tags":["kubernetes","paas","fly.io","DDD-WAW"],"title":"DDD-WAW and From Kubernetes to Paas"},{"categories":["cloud development"],"content":"On Sunday (15-01-2023) I\u0026rsquo;ve came across great read.\nThe Journey to Cloud Development: How Shopify Went All-in on Spin ","permalink":"https://johnykov.github.io/posts/the-journey-to-cloud-development/","tags":["cloud development","rails","shopify"],"title":"The Journey to Cloud Development"},{"categories":null,"content":"Picking the right Rails code style Yesterday I\u0026rsquo;ve seen this amazing 8 years old video October CincyRb - Jim Weirich on Decoupling from Rails . The mentioned video presents interesting way of separating App Code - business domain core logic - from infrastructure, Rails (ActiveRecord) specific code. As I understand this is called DDD - Domain Driven Design. There are multiple books about this concept. Just google them if interested. Going against the main flow - with DDD Rails concept - requires a lot of discipline and patience to learn, teach and adapt the whole team to stick to it. This might be a time consuming. I guess there are multiple benefits of this kind of architecture. I would look directly into one of them. Which would be FAST unit tests. The reason I fall in love with Nodejs and GO after working with Java Spring apps.\nThe result of following DDD rules is to leave domain logic in pure ruby classes - POROs - so it\u0026rsquo;s easier to unit test with rspec. Simple empty rails+rspec unit test (require rails_spec_helper?) takes 1,5 seconds to run conversely single similar rspec unit test takes 0.002 seconds to complete - huge difference - multiple orders of magnitude. Hard to achieve but gains are tempting. Maybe halfway solution is to only to Speed up Rails tests 10x by using PORO domain models The majority of rails coders follows default rails style which comes out of rails g scaffold. Mixed concerns. Controllers methods like\ndef create @room = Room.new(room_params) respond_to do |format| if @room.save format.html { redirect_to @room, notice: \u0026#39;Room was successfully created.\u0026#39; } format.json { render :show, status: :created, location: @room } else format.html { render :new } format.json { render json: @room.errors, status: :unprocessable_entity } end end end This is totally fine for even big projects especially after reading Growing Rails from people from Makandra .\nMore on DDD Rails might be found related sources:\nDDD Rails leader Arkency blog polish podcast 47. O nauce DDD i bi-temporalnych eventach domenowych z Andrzejem Krzywdą Other great Ruby on Rails resources:\nrails code quality after listening to Rails podcast ruby weekly ","permalink":"https://johnykov.github.io/DDD-rails.html","tags":["development","rails","DDD","Jim Weirich"],"title":"Rails ActiveRecord or DDD?"},{"categories":null,"content":"Some time ago we changed how Bootzooka handles HTTP requests. My goal is to compare two great tools:\ncomplete web framework scalatra 2.3.1 (latest stable) called by one of it\u0026rsquo;s project leaders a web toolkit akka-http 2.4.2 from a performance perspective. I find both of them very helpful but they work in different ways so the idea is to see how much that impacts the application and it\u0026rsquo;s users.\nWhenever you buy a car - you look at its specification. How fast it is, how amazing is the acceleration, how much petrol does it burn, how much load it can carry. I\u0026rsquo;d like to know such metrics for tools I use to build web applications. Authors don\u0026rsquo;t always publish such metrics and often Google doesn\u0026rsquo;t find any. One such metric would be to compare benchmarks but there are none so let’s make a comparison.\nFrom the Great Jez Humble\u0026rsquo;s Continuous Delivery book, introduction to chapter 9, comes the definition of app performance:\nFirst of all, let’s clear up some confusion around the terms. We’ll use the same terminology as Michael Nygard.1 To paraphrase, performance is a measure of the time taken to process a single transaction, and can be measured either in isolation or under load. Throughput is the number of transactions a system can process in a given timespan. It is always limited by some bottleneck in the system. The maximum throughput a system can sustain, for a given workload, while maintaining an acceptable response time for each individual request, is its capacity. Customers are usually interested in throughput or capacity. In real life, “performance” is often used as a catch-all term; we will try to be rather more careful in this chapter.\nSo I’ll try to find throughput and capacity for each versions of bootzooka.\nBrief details of tested tools internals The version of Scalatra that I\u0026rsquo;ve tested works in synchronous \u0026amp; blocking way while akka-http is by default \u0026ldquo;reactive\u0026rdquo; (asynchronous and non-blocking - ”reactive” trait might be easily lost when the implementation is blocking, so our code also needs to process asnychronously).\nScalatra is thread based, handling servlets and requires servlet container like jetty to run, it can delegate work to akka (from its docs, never tried this one), while akka-http is actor per request, doesn\u0026rsquo;t require a container and writing actor model code is more natural pattern to follow in this case. Both have comparably pleasant DSLs for writing routes.\nSetup Equipped with gatling.io (for generating fake traffic of user scenarios) and GCViewer (for watching a memory consumption, this is influenced by Bartek\u0026rsquo;s post to see if something spectacular is going on) I can measure what happens to my beloved framework (bootzooka) after switching web frameworks.\nThe test was performed on macbook pro, 2,5 GHz Intel Core i7 with 16 GB of ram. I use default JVM flags what is Xss=1 MB (thread stack size) and InitialHeapSize ~ 260 MB and Xmx ~ 4 GB (note: heroku 1 dyno standard is 350 MB).\n$ java -XX:+PrintFlagsFinal version uintx InitialHeapSize := 268435456 uintx MaxHeapSize := 4294967296 uintx MaxNewSize := 1431306240 uintx NewSize := 89128960 uintx OldSize := 179306496 intx ThreadStackSize = 1024 I’m running postgres 9.4 database locally with two separate schemas one for each scalatra and akka-http versions of bootzooka. So database configuration is same for each system. Gatling scenarios are being run on same local machine as bootzooka backends are deployed ( frontend is written in angular and it’s performance is fine). This configuration is a kind of “lab environment” where network latency and bandwidth doesn’t play any role, there is no data transmission over the wire what often is the main issue of webapp performance.\nScalatra bootzooka version (tag last-scalatra) Akka-http bootzooka version for this commit Repository with simple scenario for the test Provisioning The newbootzooka schema is for akka-http bootzooka version and oldbootzooka schema is for scalatra.\nexport DATABASE_URL=postgres://newbootzooka:newbootzooka@localhost:5432/newbootzooka \u0026amp;\u0026amp; \\ java -Dserver.port=8081 -Xloggc:newbootzooka-$(date +\u0026#34;%Y-%m-%d_%H-%M-%S\u0026#34;).log \\ -XX:+PrintGCDetails -XX:+PrintGCDateStamps -verbose:gc -jar new-bootzooka/bootzooka.jar export DATABASE_URL=postgres://oldbootzooka:oldbootzooka@localhost:5432/oldbootzooka \u0026amp;\u0026amp; \\ java -Dembedded-jetty.port=8082 -Xloggc:oldbootzooka-$(date +\u0026#34;%Y-%m-%d_%H-%M-%S\u0026#34;).log \\ -XX:+PrintGCDetails -XX:+PrintGCDateStamps -verbose:gc -jar old-bootzooka/bootzooka.jar Scenario It’s very basic as bootzooka doesn’t do complicated stuff. In the first step user goes to /, waits for http 200 code and in second sends post request (to /api/users/register) to register himself and awaits for success string in response body.\nScenario setup 1 Throwing at each system 200 users at once just to see what happens BootzookaRegistrationScn Bootzooka akka-http version: ./gradlew -Dserver.port=8081 loadTest First round results:\n================================================================================ ---- Global Information -------------------------------------------------------- \u0026gt; request count 400 (OK=387 KO=13 ) \u0026gt; min response time 18 (OK=18 KO=111 ) \u0026gt; max response time 3991 (OK=3991 KO=1227 ) \u0026gt; mean response time 1364 (OK=1397 KO=403 ) \u0026gt; std deviation 1226 (OK=1232 KO=331 ) \u0026gt; response time 50th percentile 957 (OK=1103 KO=333 ) \u0026gt; response time 75th percentile 2445 (OK=2446 KO=552 ) \u0026gt; mean requests/sec 79.586 (OK=77 KO=2.587 ) ---- Response Time Distribution ------------------------------------------------ \u0026gt; t \u0026lt; 800 ms 170 ( 43%) \u0026gt; 800 ms \u0026lt; t \u0026lt; 1200 ms 33 ( 8%) \u0026gt; t \u0026gt; 1200 ms 184 ( 46%) \u0026gt; failed 13 ( 3%) ---- Errors -------------------------------------------------------------------- \u0026gt; java.net.ConnectException: Connection reset by peer 13 (100.0%) ================================================================================ You can see there was 400 requests as each user makes 2 requests. There were 13 timeouts, so maybe because of JIT compilation, let\u0026rsquo;s run test a second round:\n================================================================================ ---- Global Information -------------------------------------------------------- \u0026gt; request count 400 (OK=400 KO=0 ) \u0026gt; min response time 7 (OK=7 KO=- ) \u0026gt; max response time 679 (OK=679 KO=- ) \u0026gt; mean response time 193 (OK=193 KO=- ) \u0026gt; std deviation 215 (OK=215 KO=- ) \u0026gt; response time 50th percentile 45 (OK=45 KO=- ) \u0026gt; response time 75th percentile 404 (OK=404 KO=- ) \u0026gt; mean requests/sec 171.969 (OK=171.969 KO=- ) ---- Response Time Distribution ------------------------------------------------ \u0026gt; t \u0026lt; 800 ms 400 (100%) \u0026gt; 800 ms \u0026lt; t \u0026lt; 1200 ms 0 ( 0%) \u0026gt; t \u0026gt; 1200 ms 0 ( 0%) \u0026gt; failed 0 ( 0%) ================================================================================ Looks good, how about doubling number to 400 users at once, third round:\n================================================================================ ---- Global Information -------------------------------------------------------- \u0026gt; request count 800 (OK=800 KO=0 ) \u0026gt; min response time 7 (OK=7 KO=- ) \u0026gt; max response time 1443 (OK=1443 KO=- ) \u0026gt; mean response time 440 (OK=440 KO=- ) \u0026gt; std deviation 471 (OK=471 KO=- ) \u0026gt; response time 50th percentile 200 (OK=200 KO=- ) \u0026gt; response time 75th percentile 920 (OK=920 KO=- ) \u0026gt; mean requests/sec 212.993 (OK=212.993 KO=- ) ---- Response Time Distribution ------------------------------------------------ \u0026gt; t \u0026lt; 800 ms 541 ( 68%) \u0026gt; 800 ms \u0026lt; t \u0026lt; 1200 ms 183 ( 23%) \u0026gt; t \u0026gt; 1200 ms 76 ( 10%) \u0026gt; failed 0 ( 0%) ================================================================================ No failed requests, mean req/sec ~ 212. Let\u0026rsquo;s double users for forth round:\n================================================================================ ---- Global Information -------------------------------------------------------- \u0026gt; request count 1600 (OK=1565 KO=35 ) \u0026gt; min response time 4 (OK=4 KO=159 ) \u0026gt; max response time 4167 (OK=4167 KO=1625 ) \u0026gt; mean response time 1016 (OK=1016 KO=991 ) \u0026gt; std deviation 1032 (OK=1041 KO=428 ) \u0026gt; response time 50th percentile 896 (OK=895 KO=1285 ) \u0026gt; response time 75th percentile 1515 (OK=1519 KO=1288 ) \u0026gt; mean requests/sec 228.571 (OK=223.571 KO=5 ) ---- Response Time Distribution ------------------------------------------------ \u0026gt; t \u0026lt; 800 ms 720 ( 45%) \u0026gt; 800 ms \u0026lt; t \u0026lt; 1200 ms 157 ( 10%) \u0026gt; t \u0026gt; 1200 ms 688 ( 43%) \u0026gt; failed 35 ( 2%) ---- Errors -------------------------------------------------------------------- \u0026gt; java.net.ConnectException: Connection reset by peer 35 (100.0%) ================================================================================ 2% of failed requests but no error in logs (maybe we don\u0026rsquo;t handle that case yet). And in logs I\u0026rsquo;ve found:\njava.sql.SQLTimeoutException: Timeout after 1015ms of waiting for a connection. and more:\n13:53:45.304 [main-akka.actor.default-dispatcher-82] ERROR c.s.b.Main$$anon$1 - Exception during client request processing: Task slick.backend.DatabaseComponent$DatabaseDef$$anon$2@71688eb2 rejected from java.util.concurrent.ThreadPoolExecutor@4131e49e[Running, pool size = 20, active threads = 20, queued tasks = 1000, completed tasks = 4067]\nLet\u0026rsquo;s repeat, same setup, fifth round:\n================================================================================ ---- Global Information -------------------------------------------------------- \u0026gt; request count 1600 (OK=1600 KO=0 ) \u0026gt; min response time 4 (OK=4 KO=- ) \u0026gt; max response time 1905 (OK=1905 KO=- ) \u0026gt; mean response time 378 (OK=378 KO=- ) \u0026gt; std deviation 631 (OK=631 KO=- ) \u0026gt; response time 50th percentile 57 (OK=57 KO=- ) \u0026gt; response time 75th percentile 300 (OK=300 KO=- ) \u0026gt; mean requests/sec 225.384 (OK=225.384 KO=- ) ---- Response Time Distribution ------------------------------------------------ \u0026gt; t \u0026lt; 800 ms 1310 ( 82%) \u0026gt; 800 ms \u0026lt; t \u0026lt; 1200 ms 23 ( 1%) \u0026gt; t \u0026gt; 1200 ms 267 ( 17%) \u0026gt; failed 0 ( 0%) ================================================================================ No failed requests this time,75th percentile means: 75% of requests handled within below 300 milliseconds.\nBootzooka scalatra version: ./gradlew -Dserver.port=8082 loadTest First round:\n================================================================================ ---- Global Information -------------------------------------------------------- \u0026gt; request count 400 (OK=284 KO=116 ) \u0026gt; min response time 61 (OK=61 KO=10486 ) \u0026gt; max response time 11823 (OK=11823 KO=11805 ) \u0026gt; mean response time 5800 (OK=3502 KO=11426 ) \u0026gt; std deviation 5640 (OK=5156 KO=199 ) \u0026gt; response time 50th percentile 1747 (OK=224 KO=11447 ) \u0026gt; response time 75th percentile 11470 (OK=11334 KO=11571 ) \u0026gt; mean requests/sec 31.464 (OK=22.339 KO=9.125 ) ---- Response Time Distribution ------------------------------------------------ \u0026gt; t \u0026lt; 800 ms 200 ( 50%) \u0026gt; 800 ms \u0026lt; t \u0026lt; 1200 ms 0 ( 0%) \u0026gt; t \u0026gt; 1200 ms 84 ( 21%) \u0026gt; failed 116 ( 29%) ---- Errors -------------------------------------------------------------------- \u0026gt; regex(success).find(0).exists, found nothing 116 (100.0%) ================================================================================ 116 failed request, same case let\u0026rsquo;s give a JIT a chance. Second round:\n================================================================================ ---- Global Information -------------------------------------------------------- \u0026gt; request count 400 (OK=327 KO=73 ) \u0026gt; min response time 1 (OK=1 KO=4298 ) \u0026gt; max response time 5015 (OK=5015 KO=4773 ) \u0026gt; mean response time 2016 (OK=1449 KO=4556 ) \u0026gt; std deviation 2279 (OK=2143 KO=101 ) \u0026gt; response time 50th percentile 67 (OK=53 KO=4576 ) \u0026gt; response time 75th percentile 4623 (OK=4583 KO=4627 ) \u0026gt; mean requests/sec 67.261 (OK=54.986 KO=12.275) ---- Response Time Distribution ------------------------------------------------ \u0026gt; t \u0026lt; 800 ms 222 ( 56%) \u0026gt; 800 ms \u0026lt; t \u0026lt; 1200 ms 6 ( 2%) \u0026gt; t \u0026gt; 1200 ms 99 ( 25%) \u0026gt; failed 73 ( 18%) ---- Errors -------------------------------------------------------------------- \u0026gt; regex(success).find(0).exists, found nothing 73 (100.0%) ================================================================================ 73 failed, ok it\u0026rsquo;s better then 116 but let\u0026rsquo;s keep it warming. Third round:\n================================================================================ ---- Global Information -------------------------------------------------------- \u0026gt; request count 400 (OK=357 KO=43 ) \u0026gt; min response time 1 (OK=1 KO=3261 ) \u0026gt; max response time 3929 (OK=3929 KO=3667 ) \u0026gt; mean response time 1505 (OK=1269 KO=3463 ) \u0026gt; std deviation 1626 (OK=1563 KO=109 ) \u0026gt; response time 50th percentile 291 (OK=250 KO=3468 ) \u0026gt; response time 75th percentile 3507 (OK=3462 KO=3553 ) \u0026gt; mean requests/sec 80.89 (OK=72.194 KO=8.696 ) ---- Response Time Distribution ------------------------------------------------ \u0026gt; t \u0026lt; 800 ms 229 ( 57%) \u0026gt; 800 ms \u0026lt; t \u0026lt; 1200 ms 9 ( 2%) \u0026gt; t \u0026gt; 1200 ms 119 ( 30%) \u0026gt; failed 43 ( 11%) ---- Errors -------------------------------------------------------------------- \u0026gt; regex(success).find(0).exists, found nothing 43 (100.0%) ================================================================================ 43 failed, number is decreasing but we see mean 80 req/sec with 11% of failures. Forth round:\n================================================================================ ---- Global Information -------------------------------------------------------- \u0026gt; request count 400 (OK=339 KO=61 ) \u0026gt; min response time 1 (OK=1 KO=2005 ) \u0026gt; max response time 5830 (OK=5830 KO=5528 ) \u0026gt; mean response time 2162 (OK=1648 KO=5021 ) \u0026gt; std deviation 2601 (OK=2466 KO=957 ) \u0026gt; response time 50th percentile 61 (OK=21 KO=5370 ) \u0026gt; response time 75th percentile 5412 (OK=5318 KO=5451 ) \u0026gt; mean requests/sec 58.651 (OK=49.707 KO=8.944 ) ---- Response Time Distribution ------------------------------------------------ \u0026gt; t \u0026lt; 800 ms 230 ( 58%) \u0026gt; 800 ms \u0026lt; t \u0026lt; 1200 ms 7 ( 2%) \u0026gt; t \u0026gt; 1200 ms 102 ( 26%) \u0026gt; failed 61 ( 15%) ---- Errors -------------------------------------------------------------------- \u0026gt; regex(success).find(0).exists, found nothing 61 (100.0%) ================================================================================ 61 failed, looks like won\u0026rsquo;t be better, however let\u0026rsquo;s double users to compare it with akka-http system. Fifth round:\n400 requests at once:\n================================================================================ ---- Global Information -------------------------------------------------------- \u0026gt; request count 800 (OK=572 KO=228 ) \u0026gt; min response time 1 (OK=1 KO=1993 ) \u0026gt; max response time 14464 (OK=14464 KO=14065 ) \u0026gt; mean response time 5533 (OK=2370 KO=13468 ) \u0026gt; std deviation 6667 (OK=5087 KO=1723 ) \u0026gt; response time 50th percentile 116 (OK=35 KO=13728 ) \u0026gt; response time 75th percentile 13715 (OK=144 KO=13827 ) \u0026gt; mean requests/sec 50.614 (OK=36.189 KO=14.425) ---- Response Time Distribution ------------------------------------------------ \u0026gt; t \u0026lt; 800 ms 458 ( 57%) \u0026gt; 800 ms \u0026lt; t \u0026lt; 1200 ms 5 ( 1%) \u0026gt; t \u0026gt; 1200 ms 109 ( 14%) \u0026gt; failed 228 ( 29%) ---- Errors -------------------------------------------------------------------- \u0026gt; regex(success).find(0).exists, found nothing 228 (100.0%) ================================================================================ 50 mean req/sec with 29% of failed and in app logs I see:\njava.sql.SQLTimeoutException: Timeout after 1003ms of waiting for a connection. Memory usage In both cases, memory usage is comparable, I saw same 99.97% of jvm code throughput and even almost same number of GC pauses. I have two files but nothing spectacular here. The upper window is akka-http bootzooka version the lower is scalatra version.\nnewjvm-2016-03-29_15-11-42.log oldjvm-2016-03-29_15-33-13.log Conclusion after scenario setup 1 This first scenario setup is naive and should show \u0026ldquo;something\u0026rdquo; and that is akka-http app behaves better than scalatra and continue to operate while getting bigger traffic too. Akka-http stops responding under much bigger load 800 users vs scalatra 200 users (mean 225 req/sec vs 50-80req/sec). It looks like akka-http version has better default configuration (thread pool size) and integrates well with slick (functional relational mapping tool) and hikari-cp (tool that managed database connection pool) which overall handles resources in more efficient way.\nComparison of second round of both frameworks: For comparison I\u0026rsquo;ve used gatling-reports and the legend .\nsimulation duration successCount errorCount min p50 p95 p99 max avg stddev requestPerSecond apdex rating akka-http 1.98 400 0 4 43 581 678 679 191.2 217 201.71 1 Excellent scalatra 5.48 327 73 0 65 4901 4984 5015 2014.55 2284 59.73 0.79 Fair duration = seconds succesCount = number of requests min, p50, p95, p99, max, avg, stddev = miliseconds errors duration throughput Comparison of best runs for 200 users: simulation duration successCount errorCount min p50 p95 p99 max avg stddev requestPerSecond apdex rating akka-http 1.98 400 0 4 43 581 678 679 191.2 217 201.71 1 Excellent scalatra 4.49 357 43 0 259 3770 3869 3928 1473.31 1654 79.49 0.8 Fair Comparison for 400 users: simulation duration successCount errorCount min p50 p95 p99 max avg stddev requestPerSecond apdex rating akka-http 3.41 800 0 4 199 1390 1438 1443 436.42 474 234.33 1 Excellent scalatra 15.33 572 228 0 111 14156 14398 14464 5529.42 6674 37.3 0.59 Poor errors duration throughput Comparison for 800 users (where akka-http started to have a problems): simulation duration successCount errorCount min p50 p95 p99 max avg stddev requestPerSecond apdex rating akka-http 8.69 1564 36 4 418 3095 3296 3345 1011.16 1117 180.06 0.85 Fair Hints for tuning Very often performance tests reveal that access to database is a bottleneck. In second (scalatra) of above cases we can observe it quite soon.\nFirst natural approach is to increase the database connection pool what should suffice for a while. Increasing timeout is highly undesirable because it would only slow everything down. Another practise (this time expensive) is to set a database cluster or/and queue updates and queries to database. But any of that moves requires expertise knowledge in every of touched areas (like distributed setup of databases and applications). But that is not the case here, tests are being run on defaults.\n","permalink":"https://johnykov.github.io/bootzooka-akka-http-vs-scalatra.html","tags":null,"title":"Performance akka-http vs scalatra"},{"categories":null,"content":"[2015-07-08] Update Bootzooka has been strongly simplified lately and there were some conceptual changes that is why this post is no longer valid. Also frontend part is being build by webpack now.\nOutdated: At the beginning of my carrer in Softwaremill I was working on trial project for booking company. We were building demo app starting with bootzooka as a base. We\u0026rsquo;ve changed much in that code. After that experience I brought back some of them to bootzooka.\nDefinition: Bootzooka is a simple application scaffolding project to allow quick start of development for modern web based applications. Live demo is available on http://bootzooka.softwaremill.com .\nOutdated changes: bower support (dependency management tools for frontend dependencies) commit fakeMongo for integration tests (replacing previous implementation) commit migration from twitter boostrap 2 to 3 (it\u0026rsquo;s good just to be up-to-date, right?) \u0026ldquo;angular business value module reorganization\u0026rdquo; - accordingly to good practises from sources listed below Sources: An AngularJS Style Guide for Closure Users at Google Good Practices to Build Your AngularJS Application Best Practices for Building Angular.js Apps Opinionated AngularJS styleguide for teams TODO: dockerize app add travis ci refurbish old school way of notifying users about changes keepachangelog.com , this post is a kind of changelog note ;) ","permalink":"https://johnykov.github.io/latest-bootzooka-changes.html","tags":null,"title":"Outdated bootzooka changes"},{"categories":null,"content":"As every other developer I\u0026rsquo;m a fun of easy developer life. I wish all open source projects could be build right away without any previous database or ldap mocking setup. Just fire it right away! That is why I like Vagrant so much.\nVagrant with puppet manifests [chef|ansible|bash] might help to completely separate your local development environment from office network. From now on you can work from the basement without network connection - is\u0026rsquo;t that sweet? (You might just need to mock company\u0026rsquo;s ldap server).\nThe main benefit of Vagranfile (Vagrant’s setup file) is that you can keep it as a code in your favorite VCS. Each team member will build his own local developement environment from scratch. You don’t need to distribute huge .vmdk files anymore.\nFabric is great python tool that helps you to automate many tedious tasks: copy files from one to another host, link, create users, replace configurations etc.\nFabtools is a natural extension of Fabric possibilities. The idea behind it - is comparable to that from puppet and chef. It might be considered as another provisioner.\nIn current 0.18 release of fabtools you are be able to find tomcat module which will help you to automatically provision virtual machine on you computer with apache tomcat server within few minutes.\nYou might need to install\nsudo apt-get install python-pip Vagrant Oracle VirtualBox Fabric Fabtools last two you on ubuntu can simply type in terminal:\npip install fabric pip install fabtools Example All you have to do is to create fabfile.py in your directory with vagranfile. For apache tomcat server you need java first.\nfrom fabtools import require, tomcat from fabtools.vagrant import vagrant @task def provision(): require.oracle_jdk.installed(version=\u0026#39;7u55-b13\u0026#39;) require.tomcat.installed(\u0026#39;7.0.53\u0026#39;) or go and clone my github repo , navigate to tomcat and:\nfab vagrant provision vagrant ssh As puppet manifest, fabtools fabfiles might be reused to provision remote boxes.\nReusing fabfile.py to provision remote box: When having fabfile already built for your local dev box you can then reuse it for automation of provisioning remote boxes. You can define your hosts in fabfile or you can just call\nfab -H \u0026lt;user\u0026gt;@\u0026lt;hostname\u0026gt;:\u0026lt;sshPort\u0026gt; provision Above command will install java and apache tomcat on any \u0026lt;hostname\u0026gt; with one bash call.\n","permalink":"https://johnykov.github.io/tomcat-installation-with-fabtools.html","tags":null,"title":"Fabtools - Tomcat - fast provisioning"},{"categories":null,"content":"I build web applications.\nI use directly or related technologies like REST, graphQL, Terraform, Kubernetes, Java, Typescript, Apache Kafka, github/gitlab CI/CD. Occasionally I look into DDD. I enjoy the time fixing spaghetti code, I find myself as emergency rescue plumber.\nMost often I work as senior engineer, SRE, or technical project lead developer. I\u0026rsquo;m interested in modern software engineering.\nDO MORE WITH LESS (code)\nI\u0026rsquo;ve started my career as passionate SQL and Java developer. I worked with Spring with Hibernate, CI/CD tooling and other related JVM languages like Groovy and Scala. Then I interested in Javascript and Typescript which led me to frontend jobs in AngularJS and React and eventually to NodeJS . In one of the projects I\u0026rsquo;ve learned Ruby on Rails and Kubernetes.\nIn 2021/2022 I\u0026rsquo;ve passed 2 certificate exams:\nAWS Certified Developer - Associate Confluent Certified Developer for Apache Kafka® I\u0026rsquo;m interested in:\nperformance optimisation: load tests, db indexing, caching, horizontal scalability HTMX NoSQL databases Apache Kafka streams processing Rust In my free time I like to grow up my kids, ride a bicycle, watching netflix, listening to technical podcasts changelog.com and reading books.\n","permalink":"https://johnykov.github.io/about/","tags":[],"title":"About Jan"},{"categories":null,"content":"","permalink":"https://johnykov.github.io/search/_index.es/","tags":null,"title":""},{"categories":null,"content":"","permalink":"https://johnykov.github.io/search/_index.fr/","tags":null,"title":""},{"categories":null,"content":"","permalink":"https://johnykov.github.io/search/_index.hi/","tags":null,"title":""},{"categories":null,"content":"","permalink":"https://johnykov.github.io/search/_index.jp/","tags":null,"title":""},{"categories":null,"content":"","permalink":"https://johnykov.github.io/search/_index.pl/","tags":null,"title":""},{"categories":null,"content":"","permalink":"https://johnykov.github.io/search/_index.ru/","tags":null,"title":""},{"categories":null,"content":"","permalink":"https://johnykov.github.io/search/_index.zh-cn/","tags":null,"title":""}]